Vector database được thiết kế để lưu trữ và quản lý embeddings vector.

Embeddings là đại diện dạng số của dữ liệu không phải dạng số những vẫn giữ nguyên ngữ nghĩa. Từ, tài liệu, hình ảnh, âm thanh... đều có thể được vector hóa. 

Bạn có thể sử dụng embeddings để giúp cho AI model hiểu nghĩa của input từ đó nó có thể thực hiện so sánh (comparisons) và chuyển đổi (transformations), như là tóm tắt văn bản, tìm kiếm dữ liệu liên quan, hoặc tạo hình ảnh từ văn bản...

## Vector Search

Tìm kiếm vector là một kỹ thuật tìm kiếm dựa trên các biểu diễn số (vector) của dữ liệu, thay vì dựa vào các giá trị chính xác của các trường dữ liệu. Kỹ thuật này cho phép tìm ra các mục dữ liệu có ý nghĩa ngữ cảnh tương tự nhau, ngay cả khi chúng không giống hệt nhau về mặt từ ngữ hay thuộc tính.

Mỗi mục dữ liệu (ví dụ: từ, câu, hình ảnh,…) được chuyển đổi thành một vector thông qua các mô hình embedding của trí tuệ nhân tạo (AI), chẳng hạn như các mô hình embedding của Azure OpenAI. Các vector này không chỉ chứa thông tin về bề mặt của dữ liệu mà còn nắm bắt được ý nghĩa và ngữ cảnh của dữ liệu đó. Do đó, các vector của những mục có nội dung tương tự sẽ có khoảng cách gần nhau trong không gian vector.

### Cách hoạt động của tìm kiếm vector

- Chuyển đổi truy vấn thành vector: Khi người dùng nhập truy vấn tìm kiếm, truy vấn đó cũng được chuyển thành một vector bằng cách sử dụng cùng một mô hình embedding đã được sử dụng để chuyển đổi dữ liệu.

- Tính khoảng cách giữa các vector: Quá trình tìm kiếm sau đó đo khoảng cách giữa vector của truy vấn và các vector của dữ liệu. Các chỉ số khoảng cách thường được sử dụng bao gồm:

    - Cosine similarity: Đo độ tương đồng về hướng của hai vector.
    - Euclidean distance: Đo khoảng cách không gian giữa các vector.

- Trả về các kết quả có độ tương đồng cao: Các mục dữ liệu có vector gần nhất (tức có khoảng cách nhỏ nhất so với vector truy vấn) được coi là có ý nghĩa ngữ cảnh tương tự và được trả về trong kết quả tìm kiếm.

## Vector search workflows với .NET và OpenAI

Quy trình làm việc với tìm kiếm vector và RAG trong .NET và OpenAI

1. Tạo Embeddings cho Dữ liệu: 

Sử dụng mô hình embedding của OpenAI (ví dụ: text-embedding-ada-002) để chuyển đổi từng phần dữ liệu (văn bản, đoạn trích tài liệu,...) thành các vector số học có khả năng nắm bắt ý nghĩa ngữ cảnh.

2. Lưu trữ và Lập chỉ mục Embeddings:

Sau khi tạo embeddings, bạn cần lưu trữ chúng cùng với dữ liệu gốc (hoặc tham chiếu đến dữ liệu) trong một cơ sở dữ liệu có khả năng lập chỉ mục vector. Một số lựa chọn phổ biến:
    - Azure Cosmos DB for MongoDB vCore: Hỗ trợ tìm kiếm vector một cách native.
    - Azure Cognitive Search: Có thể được tích hợp để quét, lập chỉ mục và thực hiện tìm kiếm theo vector.

Mỗi bản ghi trong cơ sở dữ liệu nên chứa dữ liệu gốc và vector embedding tương ứng. Khi thực hiện tìm kiếm, bạn sẽ so sánh embedding của truy vấn với các embedding đã lưu trữ để xác định độ tương đồng.

3. Xử lý Truy vấn từ Người dùng: 

Khi người dùng gửi truy vấn thông qua ứng dụng .NET, truy vấn đó cũng được chuyển thành embedding sử dụng cùng mô hình của OpenAI. Điều này đảm bảo rằng truy vấn và dữ liệu đều nằm trong cùng một không gian vector.

4.  Thực hiện Tìm kiếm Vector:

- Tìm kiếm theo độ tương đồng: Dùng dịch vụ tìm kiếm vector để so sánh embedding của truy vấn với các embedding đã lưu trong cơ sở dữ liệu. Hệ thống sẽ tính khoảng cách (ví dụ: cosine similarity, Euclidean distance) giữa các vector và trả về các mục có độ tương đồng cao nhất với truy vấn.
- Tích hợp tìm kiếm: Tùy thuộc vào cơ sở dữ liệu hoặc dịch vụ bạn sử dụng, bạn có thể gọi API REST hoặc sử dụng SDK .NET để thực hiện tìm kiếm vector.

5. Tổng hợp Kết quả và Sinh phản hồi bằng Mô hình Ngôn ngữ

- Bổ sung kết quả tìm kiếm vào mô hình ngôn ngữ: 
Sau khi nhận được các kết quả tìm kiếm (ví dụ: các đoạn văn bản có liên quan), bạn sẽ xây dựng một prompt cho mô hình ngôn ngữ như GPT-3.5 hoặc GPT-4. Prompt này có thể bao gồm:

    - Truy vấn ban đầu của người dùng.
    - Các thông tin/ngữ cảnh được trích xuất từ kết quả tìm kiếm vector.

Lợi ích của Mô hình RAG

Phản hồi ngữ cảnh và chính xác:
Việc bổ sung các thông tin ngữ cảnh liên quan từ dữ liệu của bạn giúp mô hình AI tạo ra các câu trả lời chính xác và phù hợp hơn với yêu cầu của người dùng.

Giảm giới hạn token của LLM:
Việc truy vấn dữ liệu và tìm kiếm vector giúp xử lý phần "nặng" của quá trình tìm kiếm ngữ cảnh, từ đó giúp bạn không phải truyền toàn bộ dữ liệu vào mô hình ngôn ngữ, vượt qua giới hạn token.

Giảm chi phí:
Nhờ khả năng truy xuất thông tin từ cơ sở dữ liệu vector, bạn không cần phải thường xuyên fine-tuning mô hình trên dữ liệu cập nhật, giúp giảm chi phí vận hành.